{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Decision Tree\n",
    "![Matrix Image](pictures/DecisionTreeModel/SololearnMachineLearningDecisionTreeModel.png \"Decision Tree\")\n",
    "\n",
    "### Gini\n",
    "\n",
    "$gini = 2*p*(1-p)$\n",
    "\n",
    "Where p is percentage of positive values\n",
    "\n",
    "![Matrix Image](pictures/DecisionTreeModel/SololearnMachineLearningDecisionTreeModelGinyGraph.png \"Gini Graph\")\n",
    "\n",
    "### Entropy\n",
    "\n",
    "$entropy = -[p*\\log_2p+(1-p)*\\log_2{(1-p)}]$\n",
    "\n",
    "![Matrix Image](pictures/DecisionTreeModel/SololearnMachineLearningDecisionTreeModelEntropyGraph.png \"Entropy Graph\")\n",
    "\n",
    "### Information Gain\n",
    "\n",
    "$Information\\ Gain = H(S)-\\dfrac{|A|}{|S|}*H(A)-\\dfrac{|B|}{|S|}*H(B)$\n",
    "\n",
    "Where:\n",
    "- H is Gini function\n",
    "- S is original data length $(|S|)$\n",
    "- A is positive data\n",
    "- B is negative data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=22)\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.predict([[3, True, 22, 1, 0, 7.25]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparing LogisticRegression vs DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree:\n",
      "accuracy: 0.7882882882882883\n",
      "precision: 0.7415730337078652\n",
      "recall: 0.7333333333333333\n",
      "\n",
      "Logistic Regression:\n",
      "accuracy: 0.7522522522522522\n",
      "precision: 0.7058823529411765\n",
      "recall: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"DecisionTree:\")\n",
    "print(\"accuracy:\", model.score(X_test, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"precision:\", precision_score(y_test, y_pred))\n",
    "print(\"recall:\", recall_score(y_test, y_pred))\n",
    "print()\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"accuracy:\", lr.score(X_test, y_test))\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"precision:\", precision_score(y_test, y_pred_lr))\n",
    "print(\"recall:\", recall_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Using entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - gini\n",
      "accuracy: 0.7801053767536342\n",
      "precision: 0.7105406907264492\n",
      "recall: 0.7156788400939873\n",
      "Decision Tree - entropy\n",
      "accuracy: 0.7722909921919634\n",
      "precision: 0.7110742497839271\n",
      "recall: 0.7063991030113105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "for criterion in ['gini', 'entropy']:\n",
    "    print(\"Decision Tree - {}\".format(criterion))\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        dt = DecisionTreeClassifier(criterion=criterion)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred = dt.predict(X_test)\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "    print(\"accuracy:\", np.mean(accuracy))\n",
    "    print(\"precision:\", np.mean(precision))\n",
    "    print(\"recall:\", np.mean(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exporting image of tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "feature_names = ['Pclass', 'male']\n",
    "dt = DecisionTreeClassifier()\n",
    "X = df[feature_names].values\n",
    "dt.fit(X, y)\n",
    "dot_file = export_graphviz(dt, feature_names=feature_names)\n",
    "\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Not working because pycharm problem\n",
    "\n",
    "# import graphviz\n",
    "# graph = graphviz.Source(dot_file)\n",
    "# graph.render(filename='tree', format='png', cleanup=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Matrix Image](pictures/DecisionTreeModel/tree.png \"Can be generated with GenerateTreeImage.py\")\n",
    "### Decision tree is prone to overfitting\n",
    "![Matrix Image](pictures/DecisionTreeModel/treeFull.png \"Can be generated with GenerateTreeImageFull.py\")\n",
    "\n",
    "This is reason why we do <b>pruning the tree </b><i>pre-pruning & post-pruning</i>\n",
    "#### Pre-pruning\n",
    "- <b>max depth </b> Only grow the tree up to a certain depth, or height of the tree.\n",
    "If the max depth is 3, there will be at most 3 splits for each datapoint.\n",
    "- <b>leaf size</b> Don’t split a node if the number of samples at that node is under a threshold\n",
    "- <b>number of leaf nodes</b> Limit the total number of leaf nodes allowed in the tree\n",
    "\n",
    "Pruning is a balance. For example, if you set the max depth too small, you won’t have much of a\n",
    "tree and you won’t have any predictive power. This is called underfitting. Similarly if the leaf\n",
    "size is too large, or the number of leaf nodes too small, you’ll have an underfit model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dt1 = DecisionTreeClassifier(max_depth=3, min_samples_leaf=2, max_leaf_nodes=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### finding best limits\n",
    "GridSearchCV has four parameters\n",
    "1. The model (in this case a DecisionTreeClassifier)\n",
    "2. Param grid: a dictionary of the parameters names and all the possible values\n",
    "3. What metric to use (default is accuracy)\n",
    "4. How many folds for k-fold cross validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'max_depth': 15, 'max_leaf_nodes': 35, 'min_samples_leaf': 1}\n",
      "best score: 0.7709600688632559\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth':[5, 15, 25],\n",
    "    'min_samples_leaf': [1,3],\n",
    "    'max_leaf_nodes': [10, 20, 35, 50]}\n",
    "dt = DecisionTreeClassifier()\n",
    "gs = GridSearchCV(dt, param_grid, scoring='f1', cv=5)\n",
    "gs.fit(X,y)\n",
    "print(\"best params:\", gs.best_params_)\n",
    "print(\"best score:\", gs.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Matrix Image](pictures/DecisionTreeModel/treeBest.png \"Can be generated with GenerateTreeImageBest.py\")\n",
    "\n",
    "- Decision tree is slow to build, but very fast predicting model.\n",
    "- Decision tree is prone to overfitting\n",
    "- Decision tree is perfect to explain prediction to non technical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}